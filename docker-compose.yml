# MemU Server Docker Compose Configuration
version: '3.8'

services:
  memu-server:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: memu-server
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      # Server settings
      - MEMU_HOST=0.0.0.0
      - MEMU_PORT=8000
      - MEMU_DEBUG=false
      
      # Memory settings
      - MEMU_MEMORY_DIR=/app/memory
      - MEMU_ENABLE_EMBEDDINGS=true
      
      # LLM Provider (change based on your needs)
      - MEMU_LLM_PROVIDER=openai
      
      # Add your API keys here or use .env file
      # - OPENAI_API_KEY=your-openai-api-key
      # - ANTHROPIC_API_KEY=your-anthropic-api-key
      # - DEEPSEEK_API_KEY=your-deepseek-api-key
    env_file:
      - .env  # Optional: load from .env file
    volumes:
      # Persist memory data
      - memu-memory:/app/memory
      # Optional: mount logs
      - memu-logs:/app/logs
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - memu-network

volumes:
  memu-memory:
    driver: local
  memu-logs:
    driver: local

networks:
  memu-network:
    driver: bridge
